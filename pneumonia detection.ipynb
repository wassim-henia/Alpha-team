{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport glob\nimport h5py\nimport shutil\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport imgaug.augmenters as iaa\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom keras import backend as K\ncolor = sns.color_palette()\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5869d878e9a5fc94ab5eb05cbd24d67bab88378"},"cell_type":"markdown","source":"Reproducibility is a great concern when doing deep learning. There was a good discussion on `KaggleNoobs` slack regarding this. We will set a numer of things in order to make sure that the results are almost reproducible(if not fully). "},{"metadata":{"_uuid":"ee4c0df90c4dfe5f2e770cb3ecf05c849fa6cd7a","trusted":true,"collapsed":true,"_cell_guid":"9957d783-26d0-4e21-b8cb-8d1412b66bdd"},"cell_type":"code","source":"import tensorflow as tf\n\n# Set the seed for hash based operations in python\nos.environ['PYTHONHASHSEED'] = '0'\n\n# Set the numpy seed\nnp.random.seed(111)\n\n# Disable multi-threading in tensorflow ops\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n\n# Set the random seed in tensorflow at graph level\ntf.set_random_seed(111)\n\n# Define a tensorflow session with above session configs\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n\n# Set the session in keras\nK.set_session(sess)\n\n# Make the augmentation sequence deterministic\naug.seed(111)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d488f59675eda4dcdab8aaafaae7263a6128c047"},"cell_type":"markdown","source":"The dataset is divided into three sets: 1) train set    2) validation set    and 3) test set.  Let's grab the dataset   "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"cell_type":"code","source":"# Define path to the data directory\ndata_dir = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray')\n\n# Path to train directory (Fancy pathlib...no more os.path!!)\ntrain_dir = data_dir / 'train'\n\n# Path to validation directory\nval_dir = data_dir / 'val'\n\n# Path to test directory\ntest_dir = data_dir / 'test'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bad0cc6b4292d08526c433fd86fea32e31e361e","trusted":true,"_cell_guid":"d2a81adb-fe02-4ec9-bd62-9d183598cf3b","collapsed":true},"cell_type":"code","source":"# Get the path to the normal and pneumonia sub-directories\nnormal_cases_dir = train_dir / 'NORMAL'\npneumonia_cases_dir = train_dir / 'PNEUMONIA'\n\n# Get the list of all the images\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n# An empty list. We will insert the data into this list in (img_path, label) format\ntrain_data = []\n\n# Go through all the normal cases. The label for these cases will be 0\nfor img in normal_cases:\n    train_data.append((img,0))\n\n# Go through all the pneumonia cases. The label for these cases will be 1\nfor img in pneumonia_cases:\n    train_data.append((img, 1))\n\n# Get a pandas dataframe from the data we have in our list \ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n\n# Shuffle the data \ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)\n\n# How the dataframe looks like?\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c827c5bbbefcea77a93ae7fb2141534e297dce08"},"cell_type":"markdown","source":"### How many samples for each class are there in the dataset?"},{"metadata":{"_uuid":"7339a4be8a266b0d8b13f1f6136370b711691f7a","trusted":true,"_cell_guid":"55a1b867-5499-4460-a435-8145c1bdff4e","collapsed":true},"cell_type":"code","source":"# Get the counts for each class\ncases_count = train_data['label'].value_counts()\nprint(cases_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=cases_count.index, y= cases_count.values)\nplt.title('Number of cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"977e06568660798f12288e7c29bba0fb35646c31","trusted":true,"_cell_guid":"294e9c52-2d9a-427c-ba19-c8f3a28b0b65","collapsed":true},"cell_type":"code","source":"# Get few samples for both the classes\npneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\nnormal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n\n# Concat the data in a single list and del the above two list\nsamples = pneumonia_samples + normal_samples\ndel pneumonia_samples, normal_samples\n\n# Plot the data \nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    img = imread(samples[i])\n    ax[i//5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i//5, i%5].set_title(\"Pneumonia\")\n    else:\n        ax[i//5, i%5].set_title(\"Normal\")\n    ax[i//5, i%5].axis('off')\n    ax[i//5, i%5].set_aspect('auto')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"422892036677e8ab0cd5eb1df2a55752611de2a6"},"cell_type":"markdown","source":"### Preparing validation data\nWe will be defining a generator for the training dataset later in the notebook but as the validation data is small, so I can read the images and can load the data without the need of a generator.  This is exactly what the code block given below is doing."},{"metadata":{"_uuid":"fa1af0731ad6ff427ff72d9d029a2a414f4d11a3","trusted":true,"_cell_guid":"4ef15f9a-b9bc-4e00-9ff5-928e287c526e","collapsed":true},"cell_type":"code","source":"# Get the path to the sub-directories\nnormal_cases_dir = val_dir / 'NORMAL'\npneumonia_cases_dir = val_dir / 'PNEUMONIA'\n\n# Get the list of all the images\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n# List that are going to contain validation images data and the corresponding labels\nvalid_data = []\nvalid_labels = []\n\n\n# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n# We will normalize the pixel values and resizing all the images to 224x224 \n\n# Normal cases\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(0, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n                      \n# Pneumonia cases        \nfor img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(1, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n    \n# Convert the list into numpy arrays\nvalid_data = np.array(valid_data)\nvalid_labels = np.array(valid_labels)\n\nprint(\"Total number of validation examples: \", valid_data.shape)\nprint(\"Total number of labels:\", valid_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eba8d9dec36028e4a49ed3b9ffc84f0d94ab861e"},"cell_type":"markdown","source":"## Augmentation\n"},{"metadata":{"_uuid":"628f0edaefe4da1d55e2e5f022314ebfeed1a2e6","trusted":true,"collapsed":true,"_cell_guid":"b38439c7-208b-4495-b994-f9c89449005b"},"cell_type":"code","source":"# Augmentation sequence \nseq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cbc776086dc1afc6b5d79346f2c29e3451e7273"},"cell_type":"markdown","source":"### Training data generator \n"},{"metadata":{"_uuid":"6288e9af327d72237ec04364ae5d14ff1d490061","trusted":true,"collapsed":true,"_cell_guid":"118d98a9-c5f4-4288-bf41-a67080657af2"},"cell_type":"code","source":"def build_model():\n    input_img = Input(shape=(224,224,3), name='ImageInput')\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n    x = MaxPooling2D((2,2), name='pool1')(x)\n    \n    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n    x = MaxPooling2D((2,2), name='pool2')(x)\n    \n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n    x = BatchNormalization(name='bn1')(x)\n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n    x = MaxPooling2D((2,2), name='pool3')(x)\n    \n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n    x = BatchNormalization(name='bn3')(x)\n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n    x = BatchNormalization(name='bn4')(x)\n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n    x = MaxPooling2D((2,2), name='pool4')(x)\n    \n    x = Flatten(name='flatten')(x)\n    x = Dense(1024, activation='relu', name='fc1')(x)\n    x = Dropout(0.7, name='dropout1')(x)\n    x = Dense(512, activation='relu', name='fc2')(x)\n    x = Dropout(0.5, name='dropout2')(x)\n    x = Dense(2, activation='softmax', name='fc3')(x)\n    \n    model = Model(inputs=input_img, outputs=x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b34d477061729a390c947d4b9ee2473b068294ec","trusted":true,"_cell_guid":"37863ed3-1814-437d-8db1-7d56283f0a87","collapsed":true},"cell_type":"code","source":"model =  build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5df7b732a3c7d4ad5d2e2b3da3f4c6a9e1ab01f"},"cell_type":"markdown","source":"We will initialize the weights of first two convolutions with imagenet weights,"},{"metadata":{"_uuid":"6ca55c4ce3478d075c36dbf29d3d1890ef6d301f","trusted":true,"_cell_guid":"556f2cd2-a824-498a-afad-824dc4d7a951","collapsed":true},"cell_type":"code","source":"# Open the VGG16 weight file\nf = h5py.File('../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n\n# Select the layers for which you want to set weight.\n\nw,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\nmodel.layers[1].set_weights = [w,b]\n\nw,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\nmodel.layers[2].set_weights = [w,b]\n\nw,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\nmodel.layers[4].set_weights = [w,b]\n\nw,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\nmodel.layers[5].set_weights = [w,b]\n\nf.close()\nmodel.summary()    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15295c609c87c11f943aa0ed24055ca65bbd57f2","trusted":true,"collapsed":true,"_cell_guid":"87cd9cae-b836-4470-84fd-56a83f5e82c8"},"cell_type":"code","source":"#opt = RMSprop(lr=0.0001, decay=1e-6)\nopt = Adam(lr=0.0001, decay=1e-5)\nes = EarlyStopping(patience=7)\nchkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\nmodel.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"890ed0a4de401a42bf54bbecb58f105a360d3c7d","trusted":true,"_cell_guid":"0c4b5c2d-d344-465c-8d20-3c628ed19292","collapsed":true},"cell_type":"code","source":"batch_size = 16\nnb_epochs = 40\n\n# Get a train data generator\ntrain_data_gen = data_gen(data=train_data, batch_size=batch_size)\n\n# Define the number of training steps\nnb_train_steps = train_data.shape[0]//batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cfc4e08fdea211ff50c400b143dad1be126e226","trusted":true,"_cell_guid":"7005e3d2-0b62-4f14-8def-ef0af971b6fd","collapsed":true},"cell_type":"code","source":"#Fit the model\nhistory = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt],\n                               class_weight={0:1.0, 1:0.4})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"135d485c94679ae8942fc0e372091d914b752b55","trusted":true,"_cell_guid":"7e366caa-87e1-4761-aaca-5d87dee2605f","collapsed":true},"cell_type":"code","source":"# Preparing test data\nnormal_cases_dir = test_dir / 'NORMAL'\npneumonia_cases_dir = test_dir / 'PNEUMONIA'\n\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\ntest_data = []\ntest_labels = []\n\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(0, num_classes=2)\n    test_data.append(img)\n    test_labels.append(label)\n                      \nfor img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(1, num_classes=2)\n    test_data.append(img)\n    test_labels.append(label)\n    \n\ntest_data = np.array(test_data)\ntest_labels = np.array(test_labels)\n\nprint(\"Total number of test examples: \", test_data.shape)\nprint(\"Total number of labels:\", test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8032be06a247d736a041f83f0f78d74ee0310a86","trusted":true,"_cell_guid":"65afc715-9f5b-4a3a-b2a9-053bd271ba94","collapsed":true},"cell_type":"code","source":"# Evaluation on test dataset\ntest_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bfc1e8956055abdb5d5bb3399509864aa635ba6","collapsed":true},"cell_type":"code","source":"# Get predictions\npreds = model.predict(test_data, batch_size=16)\npreds = np.argmax(preds, axis=-1)\n\n# Original labels\norig_test_labels = np.argmax(test_labels, axis=-1)\n\nprint(orig_test_labels.shape)\nprint(preds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a0944856f2d0666cf7c4fd90ad3e690ed17b2e7","collapsed":true},"cell_type":"code","source":"# Get the confusion matrix\ncm  = confusion_matrix(orig_test_labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, alpha=0.7,cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7429c904fed42eacc83dc385a7c83b1c47b64183","collapsed":true},"cell_type":"code","source":"# Calculate Precision and Recall\ntn, fp, fn, tp = cm.ravel()\n\nprecision = tp/(tp+fp)\nrecall = tp/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.save(\"model.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.models import load_model\nlmodel = load_model('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_loss, test_score = lmodel.evaluate(test_data, test_labels, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}